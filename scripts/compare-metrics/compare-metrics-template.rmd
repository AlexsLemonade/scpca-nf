---
params:
  reference_s3: s3://nextflow-ccdl-results/scpca-prod
  comparison_s3: s3://nextflow-ccdl-results/scpca-staging
  project_id: "all"
  download_s3: false
title: "`scpca-nf` Metrics Comparison"
subtitle: "Project: `r params$project_id`"
author: "Childhood Cancer Data Lab"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    code_folding: hide
---

```{r setup}
#| include: false

knitr::opts_chunk$set(
  echo = FALSE
)

library(ggplot2)
set.seed(1234)
```

```{r, eval = params$download_s3}
#| include: false
# get metrics files by scanning S3
if (tolower(params$project_id[1]) == "all") {
  metrics_regex <- "_metrics.json$"
} else {
  metrics_regex <- paste0("(", params$project_id, ".+_metrics.json$)", collapse = "|")
}

ref_metrics_files <- s3fs::s3_dir_ls(
  params$reference_s3,
  recurse = TRUE,
  regexp = metrics_regex
) |>
  s3fs::s3_file_url() # get signed URLs for reading

comp_metrics_paths <- s3fs::s3_dir_ls(
  params$comparison_s3,
  recurse = TRUE,
  regexp = metrics_regex
) |>
  s3fs::s3_file_url()
```

```{r, eval = params$download_s3}
#| include: false
# read metrics files from S3
ref_data <- purrr::map(ref_metrics_files, \(url) {
  jsonlite::read_json(url, simplifyVector = TRUE)
}) |>
  purrr::list_transpose() |>
  tibble::as_tibble()

comp_data <- purrr::map(comp_metrics_paths, \(url) {
  jsonlite::read_json(url, simplifyVector = TRUE)
}) |>
  purrr::list_transpose() |>
  tibble::as_tibble()

# join the two data frames
metrics_df <- dplyr::full_join(
  ref_data,
  comp_data,
  by = c("project_id", "sample_id", "library_id"),
  suffix = c(".ref", ".comp")
)
# temporary write for testing
readr::write_rds(metrics_df, "metrics.rds")
```

```{r}
#| include: false
# temporary chunk for testing
metrics_df <- readr::read_rds("metrics.rds")
```


## Project and sample changes

```{r}
# filter to get added or removed samples
lib_changes <- metrics_df |>
  dplyr::filter(if_any(starts_with("mapped_reads"), is.na)) |>
  dplyr::mutate(
    added_removed = ifelse(is.na(mapped_reads.ref), "Added", "Removed")
  ) |>
  dplyr::select(
    project_id,
    sample_id,
    library_id,
    added_removed
  )
```

Below is a table of added or removed samples and libraries.
There are **`r sum(lib_changes$added_removed == "Added")`** added libraries and **`r sum(lib_changes$added_removed == "Added")`** removed libraries.
These come from **`r dplyr::n_distinct(lib_changes$project_id)`** project(s).

```{r}
if (nrow(lib_changes) == 0) {
  knitr::asis_output(
    "<p>No added or removed libraries</p>"
  )
} else {
  DT::datatable(
    lib_changes,
    colnames = c("Project", "Sample", "Library", "Added/Removed"),
    rownames = FALSE
  )
}
```


## Processing changes {.tabset}

```{r}
processing_fields <- c(
  "droplet_filtering_method",
  "normalization_method",
  "cell_filtering_method",
  "cluster_algorithm",
  "singler_reference",
  "cellassign_reference"
)

processing_changes <- metrics_df |>
  tidyr::drop_na(starts_with("mapped_reads")) |>
  dplyr::select(
    project_id,
    sample_id,
    library_id,
    starts_with(processing_fields)
  ) |>
  tidyr::pivot_longer(
    cols = starts_with(processing_fields),
    names_to = c("field", ".value"), # .value separates into `ref` and `comp` fields
    names_sep = "\\."
  ) |>
  dplyr::filter(
    ref != comp
  )
```

### Summary

The table below (if present) shows a summary of processing changes between the reference and comparison workflow runs.
There are a total of **`r dplyr::n_distinct(processing_changes$library_id)`** libraries with processing changes.

```{r}
processing_summary <- processing_changes |>
  dplyr::count(
    field,
    ref,
    comp,
    name = "n_changed"
  )

if (nrow(processing_summary) == 0) {
  knitr::asis_output(
    "<p>No processing changes</p>"
  )
} else {
  DT::datatable(
    processing_summary,
    colnames = c("Processing field", "Reference value", "Comparison value", "Number of libraries changed"),
    rownames = FALSE
  )
}
```


### Detail

```{r}
if (nrow(processing_changes) == 0) {
  knitr::asis_output(
    "<p>No processing changes</p>"
  )
} else {
  DT::datatable(
    processing_changes,
    colnames = c("Project", "Sample", "Library", "Field", "Reference value", "Comparison value"),
    rownames = FALSE
  )
}
```
## Changes in cell and read counts

### Cell count changes {.tabset}

For each sample, we will want to first compare:

- `unfiltered_cells`
- `filtered_cells`
- `processed_cells`
- `miqc_pass_count`
- `scpca_filter_count`
- `adt_scpca_filter_count`

If there are changes in any of those, we will report those, with prominent warnings for any large changes.
What defines a large change?
Perhaps start with a change > 0.5% of the total?
Alternatively, if we see a large fraction of samples changing, we would want to note that.
If there are any changes to the number of unfiltered cells, that should be highlighted, as we do not expect this to change between runs.

#### Summary
The main display item would be a summary table, in the first tab:

| Metric | Number of samples changed | % of samples changed | Mean % change |
| ----- | --------- | --------- | ---------------- |
| `scpca_filter_count` | 100 | 20 | -10 |

We will also include a plot with a histogram of the % changes for each metric where at least one sample changed.


#### Detail

A detail table of changed samples/metrics might then look like the following:

| Sample | Metric | Reference Value | Comparison Value | Change | % change |
| ------- | ---------------- | --------------- | ---------------- | ------ | -------- |
| `SCPCS999999` | `unfiltered_cells` | 1000 | 1005 | 5 | 0.5 |


### Read count changes {.tabset}

If there are changes in the cell counts, we expect changes in the read counts as well.
So we may only want to proceed with read count changes for samples where cell counts are unchanged.
Here again, I think we should warn/highlight any changes > 0.5% of the total.
Changes to unfiltered counts should also be highlighted, as we do not expect these to change between runs.

- `unfiltered_total_counts`
- `unfiltered_total_spliced`
- `unfiltered_expressed_genes`
- `filtered_total_counts`
- `filtered_total_spliced`
- `filtered_expressed_genes`
- `processed_total_counts`
- `processed_total_spliced`
- `processed_total_logcounts`
- `processed_expressed_genes`

We will also include changes in altExps using the following fields:

- `unfiltered_altexp_total`
- `filtered_altexp_total`
- `processed_altexp_total`

These will require a bit of extra processing, in that we will probably want to extract the altExp names and add those to the field names.
For example, we would want to use a field like `unfiltered_altexp_total_adt` in the comparison table.


Again, we would report only changed metrics, starting with a summary table:

| Metric | Number of samples changed | % of samples changed | Mean % change |
| ----- | --------- | --------- | ---------------- |
| `scpca_filter_count` | 100 | 20 | -10 |

We could then list individual samples with changes, similar to the cell count table.

## Analysis changes

### Highly variable genes

Here we will report changes in the sets of HVGs, both in the set of genes and the order.

### Clustering

Report changes in the number of clusters, as well as changes in the sizes of the assigned clusters.
We will ignore changes in the ordering of clusters by sorting by cluster size before comparisons.
As a summary statistic, we might use adjusted Rand index (ARI) or adjusted mutual information (AMI) to compare the two sets of clusters, reporting when we are well below 1.

### Cell type assignments

Report changes to the set of cell types assigned, and to the number of cells for each cell type.
This will include SingleR, CellAssign and consensus cell types, if present.

My initial thought is to use the Euclidean distance between the sets of cell type assignments here (since the assignment values do matter), though we could also look at ARI or AMI.


## Session Info
<details>
<summary>Click to expand</summary>
```{r}
sessionInfo()
```
</details>
