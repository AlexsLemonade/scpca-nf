// user_template.config
// An example template for use with the scpca-nf Nextflow workflow.


/*
Global parameters for scpca-nf
------------------------------
The values presented here are examples, and should be replaced with
the correct paths to any indicated files or other values that need to be set.
*/

params.run_metafile = 'example_run_metadata.tsv' // Input run metadata table
params.sample_metafile = 'example_sample_metadata.tsv' // Input sample metadata table

params.outdir = "scpca_out" // Output base directory for results

params.run_ids = "All"  // Which samples or libraries to process
/*
Note: Although the name of this parameter is `run_ids`, any ids found in
  `scpca_run_id`, `scpca_library_id`, or `scpca_sample_id` can be used.
  By default this is set to "All", but to change to a specific subset,
  use a comma separated list e.g., "SCPCR000001,SCPCR000002"
  Optionally, `run_ids` can be set at the command line with `--run_ids SCPCR000003`
*/

params.project_celltype_metafile = "example_project_celltype_metadata.tsv" // Input project celltype metadata table, only used if you are performing cell type annotation


/*
Parameters to set when performing cell type annotation with custom references
------------------------------
The values presented here are examples, and should be replaced with
the correct paths to any indicated files or other values that need to be set.
*/

params.singler_models_dir = "custom_references/singler_models" // Path to directory containing custom SingleR model file(s)
params.cellassign_reference_dir = "custom_references/cellassign_references" // Path to directory containing custom CellAssign reference file(s)


// Spaceranger container, only required if using spatial transcriptomics workflow
params.SPACERANGER_CONTAINER = ''


/*
Profile settings for the workflow execution environment
-------------------------------------------------------
Here we provide an example using slurm as the executor system.
For information about available process executors and their options, see https://www.nextflow.io/docs/latest/executor.html
This profile should be adjusted based on the details of your system and can be invoked at runtime with
`-profile cluster` (or whatever name you have chosen)

For more information on setting up profiles see https://www.nextflow.io/docs/latest/config.html#config-profiles
*/

profiles {
  cluster { // the profile name: all settings for the 'cluster' profile are within this block
    process {
      executor = 'slurm'
      // Queue name for your cluster
      queue = 'normal'
      // Resource limits for the cluster
      resourceLimits = [cpus: 24, memory: 128.GB]
      // Optionally set the location for process working files.
      // The below setting assumes an environment variable $SCRATCH is set on your cluster.
      scratch = "$SCRATCH"
      // If your HPC requires software to be loaded as a module, otherwise this line can be removed
      beforeScript = 'module load singularity'
    }
    // singularity is often required on HPC in place of docker
    singularity {
      enabled = true
      autoMounts = true
      // If you pre-pull container images (i.e., if nodes do not have internet access)
      // then the nextflow singularity cache directory should be specified.
      // This setting is optional otherwise, though you may get a warning if it is not set,
      // and a default location will be used.
      // cacheDir = "$HOME/nextflow/singularity"
    }
    docker.enabled = false
    // If access to protected resources on AWS is not required, it may be more
    // convenient/compatible to get reference files on S3 anonymously
    aws.client.anonymous = true
  }
}
