// user_template.config
// An example template for use with the scpca-nf Nextflow workflow.


/*
Global parameters for scpca-nf
------------------------------
The values presented here are examples, and should be replaced with
the correct paths to any indicated files or other values that need to be set.
*/

params.run_metafile = 'example_run_metadata.tsv' // Input run metadata table
params.sample_metafile = 'example_sample_metadata.tsv' // Input sample metadata table

params.outdir = "scpca_out" // Output base directory for results

params.run_ids = "All"  // Which samples or libraries to process
/*
Note: Although the name of this parameter is `run_ids`, any ids found in
  `scpca_run_id`, `scpca_library_id`, or `scpca_sample_id` can be used.
  By default this is set to "All", but to change to a specific subset,
  use a comma separated list e.g., "SCPCR000001,SCPCR000002"
  Optionally, `run_ids` can be set at the command line with `--run_ids SCPCR000003`
*/

params.project_celltype_metafile = "example_project_celltype_metadata.tsv" // Input project celltype metadata table, only used if you are performing cell type annotation

/*
Available computational resources
---------------------------------
Adjust the following parameters to match the resources available on your system or cluster.
  While most parts of scpca-nf will run with fewer resources than the defaults listed below,
  be aware that some processes (notably spatial transcriptomics and genetic demultiplexing) may
  fail if insufficient resources are available.
*/
params.max_cpus = 24 // Maximum number of cpu cores to use for a single process
params.max_memory = 96.GB // Maximum memory to use for a single process



// Spaceranger container, only required if using spatial transcriptomics workflow
params.SPACERANGER_CONTAINER = ''


/*
Profile settings for the workflow execution environment
-------------------------------------------------------
Here we provide an example using slurm as the executor system.
For information about available process executors and their options, see https://www.nextflow.io/docs/latest/executor.html
This profile should be adjusted based on the details of your system and can be invoked at runtime with
`-profile cluster` (or whatever name you have chosen)

For more information on setting up profiles see https://www.nextflow.io/docs/latest/config.html#config-profiles
*/

profiles{
  cluster { // the profile name: all settings for the 'cluster' profile are within this block
    process {
      executor = 'slurm'
      // Queue name for your cluster
      queue = 'normal'
      // Optionally set the location for process working files.
      // The below setting assumes an environment variable $SCRATCH is set on your cluster.
      scratch = "$SCRATCH"
      // If your HPC requires software to be loaded as a module, otherwise this line can be removed
      beforeScript = 'module load singularity'
    }
    // singularity is often required on HPC in place of docker
    singularity {
      enabled = true
      autoMounts = true
      // If you pre-pull container images (i.e., if nodes do not have internet access)
      // then the nextflow singularity cache directory should be specified.
      // This setting is optional otherwise, though you may get a warning if it is not set,
      // and a default location will be used.
      // cacheDir = "$HOME/nextflow/singularity"
    }
    docker.enabled = false
    // If access to protected resources on AWS is not required, it may be more
    // convenient/compatible to get reference files on S3 anonymously
    aws.client.anonymous = true
  }
}


/*
Parameters to set when performing cell type annotation with custom references
------------------------------
The values presented here are examples, and should be replaced with
the correct paths to any indicated files or other values that need to be set.
*/

params.singler_models_dir = "directory/containing/the/singler/model/file"
params.cellassign_reference_dir = "directory/containing/the/cellassign/reference/file"
